{
  "hash": "ca93832f52d1aa4803fae03cc4fd936a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"AI Transcription from R using Whisper: Part 2\"\ndescription: \"Speedup on Windows using WSL2 and CUDA\"\nauthor: \"Jeffrey Girard\"\ndate: \"2024-08-16\"\nimage: whisper.webp\ndraft: false\ncategories:\n  - teaching\n  - audio\n  - AI\ncomments:\n  utterances: \n    repo: jmgirard/affcomlab\n    label: whisper2024b\n---\n\n\n\n:::{.callout-warning}\nThis post has been replaced by [a new one](../whisper2024c/index.qmd), which makes things considerably easier. I am keeping this one up mostly for posterity.\n:::\n\n## Introduction\nIn a [previous blog post](../whisper2024/index.qmd), I discussed using the audio.whisper R package to do local, AI-based audio transcription. It worked well but was prohibitively slow (e.g., ~1 minute to process each second of audio). In this blog post, I will discuss how to achieve considerable speed improvements on Windows through a combination of hardware and software. Parts will be more technical but hang in there and I'll do my best to make it achievable. \n\nBefore we dive into things, I'll provide a brief overview of all the steps. \n\n1. Check that our computer's hardware supports CUDA\n1. Install/update the NVIDIA graphics driver on Windows\n1. Install and update the Windows Subsystem for Linux (WSL2) on Windows\n1. Install and setup the Ubuntu operating system via WSL2\n1. Install the CUDA Toolkit for WSL on Ubuntu\n1. Install R and dependency packages on Ubuntu\n1. Install audio.whisper R package with CUDA support on Ubuntu\n1. Test and time the model\n\n## Check for CUDA Support\n\nThis post assumes that you are using the Windows operating system and that your computer's graphics card supports [CUDA](https://developer.nvidia.com/cuda-faq). To check that this is the case, first look up your graphics card's model number. An easy way to do this on Windows 10/11 is to click on the desktop search bar (bottom-left of the screen next to the windows icon) and type in \"Device Manager.\" Then click the arrow next to \"Display adapters\" and find your graphics card's model name. On my computer, it says \"NVIDIA GeForce RTX 2060.\" Then go to  [this link](https://developer.nvidia.com/cuda-gpus) and click the \"CUDA-Enabled NVIDIA Quadro and NVIDIA RTX\" and \"CUDA-Enabled GeForce and TITAN Products\" blocks to open their accordions. Then search for your graphics card's model number (the left tables are for desktop cards and the right tables are for notebook cards). I found \"GeForce RTX 2060\" on the list under GeForce and TITAN Products with a compute capability of 7.5. Thus, my card is supported!\n\n## Install the Newest NVIDIA Graphics Driver\n\nDownload and install the newest graphics driver for your card from [NVIDIA](https://www.nvidia.com/Download/index.aspx#). You should choose the Game Ready version. Note that you should *not* install the CUDA toolkit on Windows as doing so may confuse things and lead to issues later on (as we will be installing the CUDA toolkit for WSL in a later step).\n\n## Install and Update the Windows Subsystem for Linux\n\nOpen the Microsoft Store app (e.g., using the desktop search bar) and search for the \"Windows Subsystem for Linux.\" If it doesn't come up in the search results, you may already have it installed - you can check this by clicking the \"Library\" button on the left sidebar in the app and searching for it there. If it does come up, click on the Install button. If you can't find it, then open the Command Prompt app (e.g., using the desktop search bar) and type or paste the following command: `wsl --install`. After it install using any method, it will ask you to restart your computer. Once restarted, open the Command Prompt app again and type or paste the following command: `wsl --update`. This will ensure that you have the most recent version of WSL2 installed.\n\n## Install and Setup Ubuntu\n\nIn the Command Prompt app, type or paste the following command: `wsl --install Ubuntu`. This will install the Ubuntu Linux operating system over the course of several minutes. After installation, it will prompt you to create a UNIX username and password. Use whatever you want but don't lose this information as you will need it again later. \n\n## Install the CUDA Toolkit for WSL\n\nIn the Ubuntu console (which is opened automatically after Ubuntu is installed), enter or paste the following commands to install the CUDA Toolkit for WSL-Ubuntu. It will ask you to enter your password (created in the previous step) and may take several minutes to complete.\n\n```default\nwget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.1-1_all.deb\nsudo dpkg -i cuda-keyring_1.1-1_all.deb\nsudo apt-get update\nsudo apt-get -y install cuda-toolkit\n```\n\n:::{.callout-important}\nDo not install any NVIDIA graphics drivers on Ubuntu directly (i.e., install `cuda-toolkit` and not `cuda` or `cuda-drivers`). Ubuntu will inherit the Windows drivers you installed in a previous step via WSL.\n\nIf you get timeout errors when trying to install things on WSL, check to make sure that you are not connected to a VPN on Windows as this can mess things up.\n:::\n\n## Install R on Ubuntu\n\nIn the Ubuntu console, enter or paste the following commands to install R and other packages commonly used by R. You may have to hit ENTER and type `Y` several times when prompted to do so.\n\n```default\nwget -qO- https://cloud.r-project.org/bin/linux/ubuntu/marutter_pubkey.asc | sudo tee -a /etc/apt/trusted.gpg.d/cran_ubuntu_key.asc\nsudo add-apt-repository \"deb https://cloud.r-project.org/bin/linux/ubuntu $(lsb_release -cs)-cran40/\"\nsudo apt install -y --no-install-recommends r-base\nsudo apt-get install -y libcurl4-openssl-dev libssl-dev libxml2-dev libudunits2-dev libgdal-dev cargo libfontconfig1-dev libcairo2-dev\nsudo add-apt-repository ppa:c2d4u.team/c2d4u4.0+\nsudo apt upgrade\nsudo apt install -y --no-install-recommends r-cran-devtools r-cran-av r-cran-tidyverse\n```\n\n## Install audio.whisper with CUDA Support on Ubuntu\n\nIn the Ubuntu console, type or paste the following command: `sudo R` to open the R console. You will then need to set several environmental variables before installing the audio.whisper package from GitHub. Do so by entering or pasting the following commands into the R console:\n\n```r\nSys.setenv(PATH = sprintf(\"%s:/usr/local/cuda/bin\", Sys.getenv(\"PATH\")))\nSys.setenv(CUDA_PATH = \"/usr/local/cuda\")\nSys.setenv(WHISPER_CUBLAS = \"1\")\nremotes::install_github(\"bnosac/audio.whisper\")\n```\n\n## Test and Time the Model\n\n### Base Model and Short Audio Clip\n\nIn the R console, load the audio.whisper package and try it out on the JFK clip that took so long to process in the previous blog post. Note that there will be one important change to the commands from before. This time, when we load the model using the `whisper()` function, we will add the `use_gpu = TRUE` argument.\n\n```r\n# Load the package from library\nlibrary(audio.whisper)\n\n# Download or load from file the desired model (with GPU support)\nmodel <- whisper(\"base\", use_gpu = TRUE)\n\n# Construct file path to example audio file in package data\njfk <- system.file(package = \"audio.whisper\", \"samples\", \"jfk.wav\")\n\n# Run English transcription using the downloaded whisper model\nout <- predict(model, newdata = jfk, language = \"en\")\n\n# Print transcript\nout$data\n```\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> segment </th>\n   <th style=\"text-align:right;\"> segment_offset </th>\n   <th style=\"text-align:left;\"> from </th>\n   <th style=\"text-align:left;\"> to </th>\n   <th style=\"text-align:left;\"> text </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> 00:00:00.000 </td>\n   <td style=\"text-align:left;\"> 00:00:07.600 </td>\n   <td style=\"text-align:left;\"> And so my fellow Americans, ask not what your country can do for you, </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> 00:00:07.600 </td>\n   <td style=\"text-align:left;\"> 00:00:10.600 </td>\n   <td style=\"text-align:left;\"> ask what you can do for your country. </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\nThe results look good/the same as before, but check out the timing!!!\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nout$timing\n## $transcription_start\n## [1] \"2024-11-10 12:34:19 CST\"\n## \n## $transcription_end\n## [1] \"2024-11-10 12:34:20 CST\"\n## \n## $transcription_duration\n## Time difference of 0.006911568 mins\n```\n:::\n\n\n\n### Large Model and Long Audio Clip\n\nWith such a boost in speed, we can afford to try a larger model (e.g., `\"large-v3\"`) on a longer audio clip (e.g., a 1.35 min [poetry reading](https://ubu.com/media/sound/malanga_gerard/archives/Malanga-Gerard_Archives_01-Gerard-Malanga_To-The-Young-Model-Name-Unknown.mp3) by Gerard Malanga that is rather noisy and therefore a good test of the model's accuracy in real-world settings). This is also a chance to show how to process a file downloaded from the internet, in case that is of interest to any readers. We'll use the following commands in the R console in Ubuntu:\n\n```r\n# Load package from library (it was installed earlier via apt)\nlibrary(av)\n\n# Download audio file from ubu.com\ndownload.file(\n  url = \"https://ubu.com/media/sound/malanga_gerard/archives/Malanga-Gerard_Archives_01-Gerard-Malanga_To-The-Young-Model-Name-Unknown.mp3\", \n  destfile = \"malanga.mp3\", \n  mode = \"wb\"\n)\n\n# Convert audio from mp3 to 16 kHz wav\nav_audio_convert(\n  \"malanga.mp3\", \n  output = \"malanga.wav\", \n  format = \"wav\", \n  sample_rate = 16000\n)\n\n# Download or load from file the large model with GPU support\nmodel <- whisper(\"large-v3\", use_gpu = TRUE)\n\n# Run English transcription using the downloaded whisper model\nout <- predict(model, newdata = \"output.wav\", language = \"en\")\n\n# Print the transcript\nout$data\n```\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> segment </th>\n   <th style=\"text-align:right;\"> segment_offset </th>\n   <th style=\"text-align:left;\"> from </th>\n   <th style=\"text-align:left;\"> to </th>\n   <th style=\"text-align:left;\"> text </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> 00:00:00.000 </td>\n   <td style=\"text-align:left;\"> 00:00:06.000 </td>\n   <td style=\"text-align:left;\"> Gary Malanga will read me some poems which are shortly to be illustrated by Andy Warhol. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> 00:00:06.000 </td>\n   <td style=\"text-align:left;\"> 00:00:10.000 </td>\n   <td style=\"text-align:left;\"> The poems, as far as I can tell, do not relate particularly to this exhibit, </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> 00:00:10.000 </td>\n   <td style=\"text-align:left;\"> 00:00:13.000 </td>\n   <td style=\"text-align:left;\"> but Mr. Malanga thought it would be an appropriate setting for his poetry. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> 00:00:13.000 </td>\n   <td style=\"text-align:left;\"> 00:00:17.000 </td>\n   <td style=\"text-align:left;\"> The length of the reading will be about 45 minutes. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> 00:00:17.000 </td>\n   <td style=\"text-align:left;\"> 00:00:19.000 </td>\n   <td style=\"text-align:left;\"> Thank you so much for your patience, Mr. Malanga. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 6 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> 00:00:19.000 </td>\n   <td style=\"text-align:left;\"> 00:00:26.000 </td>\n   <td style=\"text-align:left;\"> Can everyone hear me? </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 7 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> 00:00:26.000 </td>\n   <td style=\"text-align:left;\"> 00:00:33.000 </td>\n   <td style=\"text-align:left;\"> This poem is actually the first poem I ever wrote in this series of fashion poems, </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 8 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> 00:00:33.000 </td>\n   <td style=\"text-align:left;\"> 00:00:38.000 </td>\n   <td style=\"text-align:left;\"> entitled \"To a Young Model Name Unknown,\" photographed by Francesco Scuvullo. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 9 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> 00:00:38.000 </td>\n   <td style=\"text-align:left;\"> 00:00:47.000 </td>\n   <td style=\"text-align:left;\"> The Peckin Peck girl applauds the strategy of Hadley Kashmir, </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 10 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> 00:00:47.000 </td>\n   <td style=\"text-align:left;\"> 00:00:52.000 </td>\n   <td style=\"text-align:left;\"> now gentle country air left, to go calling in the afternoon, </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 11 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> 00:00:52.000 </td>\n   <td style=\"text-align:left;\"> 00:00:56.000 </td>\n   <td style=\"text-align:left;\"> pale gray, flannel-dressed, gracefully princessed, </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 12 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> 00:00:56.000 </td>\n   <td style=\"text-align:left;\"> 00:01:03.000 </td>\n   <td style=\"text-align:left;\"> its gray collar deeply cut, filled with a fluff of gray rabbit fur. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 13 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> 00:01:03.000 </td>\n   <td style=\"text-align:left;\"> 00:01:07.000 </td>\n   <td style=\"text-align:left;\"> The new country look of the jumpsuit opposite. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 14 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> 00:01:07.000 </td>\n   <td style=\"text-align:left;\"> 00:01:14.000 </td>\n   <td style=\"text-align:left;\"> Here, fresh, bright and Irish in white, stitched sheer navy blue wool, </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 15 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> 00:01:14.000 </td>\n   <td style=\"text-align:left;\"> 00:01:20.000 </td>\n   <td style=\"text-align:left;\"> Irish country airs, the changing outline of Irish fashion. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 16 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:left;\"> 00:01:20.000 </td>\n   <td style=\"text-align:left;\"> 00:01:21.780 </td>\n   <td style=\"text-align:left;\"> Thank you. </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\nThe results look really good despite the background noise. The only errors I noticed were line 11, I think he says \"princess shaped\" rather than \"princessed\" (though I could be wrong) and in line 16, I can't hear him say \"Thank you.\" so that may have been hallucinated (or perhaps in the background). Not bad at all. And check out the timing.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nout$timing\n## $transcription_start\n## [1] \"2024-08-16 13:33:07 CDT\"\n## \n## $transcription_end\n## [1] \"2024-08-16 13:33:19 CDT\"\n## \n## $transcription_duration\n## Time difference of 0.1988164 mins\n```\n:::\n\n\n\n## Wrap-up\n\nIf you want to save the transcript, you can enter the following command in the R console: `saveRDS(out, \"malanga.rds\")` and it will create a serialized R data file containing all the transcript data (e.g., text and time stamps). By default, this file will be saved in the same folder on your Windows file system that you ran the Command Prompt app from (e.g., \"C:/Users/jeffg\"). However, you can save anywhere using WSL's `/mnt/` system. For example, if you wanted to save it to \"C:/Users/jeffg/Desktop\", then you would use `\"/mnt/c/users/jeffg/Desktop/malanga.rds\"` as the second argument to `saveRDS()`. Or if you wanted to save it to a mapped network drive like \"Z:/affcomlab/transcription\", then you would use `\"/mnt/z/affcomlab/transcription/malanga.rds\"`.\n\nThat wraps up this blog post. In the next part, I will discuss more practical aspects of using this technology. For example, I'll talk about how to generate a list of audio/videos files on your hard drive (or elsewhere) and then iterate over them to create transcripts from many files all at once.\n\n*Part 3 coming soon...*\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}